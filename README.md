# How this repository was created:
We gathered a good amount of papers on bias and fairness in AI. We then created the 3 CSV files that you can find in here, which include:
1. Different taxonomies proposed in each paper
2. Datasets that have been analysed on fairness and bias and extensive information about each (where found).
3. Tools that have been analysed on fairness and bias and extensive information about each (where found).

For each instance, we include only the information available in the paper which we gather information from. In case a dataset or tool is found in different sources, we create a separate instance for the new information (especially where definitione etc are available.

We do an extensive analysis, especially based on visualisations, to find a common "map" to analyse how:
1. The different taxonomies differ.
2. The definitions differ (e.g. by creating wordclouds).
3. Which datasets have been analysed more and why.
4. Which are the most common types of bias in these datasets.
5. Which tools are mostly used and why (e.g. "are they actually able to mitigate all types of bias? Why do they have the tendency to generalise in many cases?").
6. Visualisations that show how one problem is reflected to another (e.g. 
