Paper,Authors,Types of bias,,,Synonyms,Definition,Notes,Common metrics
,,Level 1,Level 2,Level 3,,,,
1. A Framework for Understanding Sources of Harm throughout the Machine Learning Life Cycle,"Harini Suresh, John Guttag",Historical,-,-,-,"Historical bias arises even if data is perfectly measured and sampled, if the world as it is or was leads to a model that produces harmful outcomes.",,
,,Representation,-,-,-,"Representation bias occurs when the development sample underrepresents some part of the population, and subsequently fails to generalize well for a subset of the use population.",,
,,Measurement,-,-,-,"Measurement bias occurs when choosing, collecting, or computing features and labels to use in a prediction problem.",,
,,Aggregation,-,-,-,Aggregation bias arises when a one-size-fits-all model is used for data in which there are underlying groups or types of examples that should be considered differently.,,
,,Learning,-,-,-,Learning bias arises when modeling choices amplify performance disparities across different examples in the data.,,
,,Evaluation,-,-,-,Evaluation bias occurs when the benchmark data used for a particular task does not represent the use population.,,
,,Deployment,-,-,-,Deployment bias arises when there is a mismatch between the problem a model is intended to solve and the way in which it is actually used.,,
2. A Survey on Bias and Fairness in Machine Learning,"NINAREH MEHRABI, FRED MORSTATTER, NRIPSUTA SAXENA, KRISTINA LERMAN, ARAM GALSTYAN",Data to Algorithm,,-,-,,,
,,,Measurement,-,-,"Measurement, or reporting, bias arises from how we choose, utilize, and measure particular features.",,
,,,Omitted Variable,-,-,Omitted variable bias4 occurs when one or more important variables are left out of the model.,,
,,,Representation,-,-,Representation bias arises from how we sample from a population during data collection process.,,
,,,Aggregation,,-,Aggregation bias (or ecological fallacy) arises when false conclusions are drawn about individuals from observing the entire population.,,
,,,,Simpson’s Paradox,-,Simpson’s paradox is a type of aggregation bias that arises in the analysis of heterogeneous data.,,
,,,,Modifiable Areal Unit Problem,-,"Modifiable Areal Unit Problem is a statistical bias in geospatial analysis, which arises when modeling data at different levels of spatial aggregation.",,
,,,Sampling,-,-,"Sampling bias is similar to representation bias, and it arises due to non-random sampling of subgroups.",,
,,,Longitudinal Data Fallacy,,-,"Researchers analyzing temporal data must use longitudinal analysis to track cohorts over time to learn their behavior. Instead, temporal data is often modeled using cross-sectional analysis, which combines diverse cohorts at a single time point. The heterogeneous cohorts can bias cross-sectional analysis, leading to different conclusions than longitudinal analysis.",,
,,,Linking,,-,"Linking bias arises when network attributes obtained from user connections, activities, or interactions differ and misrepresent the true behavior of the users.",,
,,Algorithm to User,,,-,,,
,,,Algorithmic,-,-,Algorithmic bias is when the bias is not present in the input data and is added purely by the algorithm.,,
,,,User Interaction,,-,User Interaction bias is a type of bias that can not only be observant on the Web but also get triggered from two sources—the user interface and through the user itself by imposing his/her self-selected biased behavior and interaction,,
,,,,Presentation,-,Presentation bias is a result of how information is presented,,
,,,,Ranking,-,The idea that top-ranked results are the most relevant and important will result in attraction of more clicks than others.,,
,,,Popularity,-,-,"Items that are more popular tend to be exposed more. However, popularity metrics are subject to manipulation",,
,,,Emergent,-,-,"Emergent bias occurs as a result of use and interaction with real users. This bias arises as a result of change in population, cultural values, or societal knowledge usually some time after the completion of design",,
,,,Evaluation,-,-,Evaluation bias happens during model evaluation. This includes the use of inappropriate and disproportionate benchmarks for evaluation of applications.,,
,,User to Data,,,-,,,
,,,Historical,-,-,Historical bias is the already existing bias and socio-technical issues in the world and can seep into from the data generation process even given a perfect sampling and feature selection,,
,,,Population,-,-,"Population bias arises when statistics, demographics, representatives, and user characteristics are different in the user population of the platform from the original target population.",,
,,,Self-selection,-,-,Self-selection bias4 is a subtype of the selection or sampling bias in which subjects of the research select themselves.,,
,,,Social,-,-,Social bias happens when others’ actions affect our judgment.,,
,,,Behavioral,-,-,"Behavioral bias arises from different user behavior across platforms, contexts, or different datasets.",,
,,,Temporal,-,-,Temporal bias arises from differences in populations and behaviors over time.,,
,,,Content Production,-,-,"Content Production bias arises from structural, lexical, semantic, and syntactic differences in the contents generated by users.",,
3. A Review on Fairness in Machine Learning,"DANA PESSACH, EREZ SHMUELI",Biases already included in the datasets used for learning,-,-,-,"Biases already included in the datasets used for learning are based on biased device measurements, historically biased human decisions, erroneous reports, or other reasons.",,
,,Biases caused by missing data,-,-,-,Biases caused by missing data result in datasets that are not representative of the target population.,,
,,Biases that stem from algorithmic objectives,-,-,-,Biases that stem from algorithmic objectives aim at minimizing overall aggregated prediction errors and therefore benefit majority groups over minorities.,,
,,Biases caused by “proxy” attributes for sensitive attributes,-,-,-,"Biases caused by “proxy” attributes for sensitive attributes. Sensitive attributes differentiate privileged and unprivileged groups, such as race, gender, and age, and are typically not legitimate for use in decision making. Proxy attributes are non-sensitive attributes that can be exploited to derive sensitive attributes. In the case that the dataset contains proxy attributes, the ML algorithm can implicitly make decisions based on the sensitive attributes under the cover of using presumably legitimate attributes",,
4. Towards a Standard for Identifying and Managing Bias in Artificial Intelligence (NIST),"Reva Schwartz, Apostol Vassilev, Kristen Greene, Lori Perine, Andrew Burt, Patrick Hall",HUMAN,,,-,Human biases reflect systematic errors in human thought based on a limited number of heuristic principles and predicting values to simpler judgmental operations. These biases are often implicit and tend to relate to how an individual or group perceives information to make a decision or fill in missing or unknown information.,,
,,,INDIVIDUAL,,-,,,
,,,,automation complacency,-,When humans over-rely on automated systems or have their skills attenuated by such over-reliance.,,
,,,,consumer,-,"Arises when an algorithm or platform provides users with a new venue within which to express their biases, and may occur from either side, or party, in a digital interaction.",,
,,,,mode confusion,-,"When modal interfaces confuse human operators, who misunderstand which mode the system is using, taking actions which are correct for a different mode but incorrect for their current situation.",,
,,,,cognitive,-,A broad term referring generally to a systematic pattern of deviation from rational judgement and decision-making.,,
,,,,anchoring,-,"A cognitive bias, the influence of a particular reference point or anchor on people’s decisions. Often more fully referred to as anchoring-and-adjustment, or anchoring-and-adjusting: after an anchor is set, people adjust insufficiently from that anchor point to arrive at a final answer. Decision makers are biased towards an initially presented value.",,
,,,,"availability heuristic",-,"Also referred to as availability bias. A mental shortcut whereby people tend to overweight what comes easily or quickly to mind, meaning that what is easier to recall—e.g., more “available”—receives greater emphasis in judgement and decision-making",,
,,,,confirmation,-,"Also called confirmatory bias, a cognitive bias where people tend to prefer information that aligns with, or confirms, their existing beliefs. People can exhibit confirmation bias in the search for, interpretation of, and recall of information.",,
,,,,Dunning-Kruger effect,-,"A cognitive bias, the tendency of people with low ability in a given area or task to overestimate their self-assessed ability. Typically measured by comparing self-assessment with objective performance, often called subjective ability and objective ability, respectively.","Typically measured by comparing self-assessment with objective performance, often called subjective ability and objective ability, respectively.",
,,,,implicit,-,"An unconscious belief, attitude, feeling, association, or stereotype that can affect the way in which humans process information, make decisions, and take actions.",,
,,,,loss of situational awareness,-,"When automation leads to humans being unaware of their situation such that, when control of a system is given back to them in a situation where humans and machines cooperate, they are unprepared to assume their duties. This can be a loss of awareness over what automation is and isn’t taking care of. ",,
,,,,user interaction,-,"Arises when a user imposes their own self-selected biases and behavior during interaction with data, output, results, etc.",,
,,,,behavioral,-,"Systematic distortions in user behavior across platforms or contexts, or across users represented in different datasets.",,
,,,,interpretation,-,A form of information processing bias that can occur when users interpret algorithmic outputs according to their internalized biases and views.,,
,,,,Rashomon effect or principle,-,"Refers to differences in perspective, memory and recall, interpretation, and reporting on the same event from multiple persons or witnesses.",,
,,,,"selective adherence",-,Decision-makers’ inclination to selectively adopt algorithmic advice when it matches their pre-existing beliefs and stereotypes,,
,,,,streetlight effect,-,A bias whereby people tend to search only where it is easiest to look.,,
,,,,"annotator reporting",-,"When users rely on automation as a heuristic replacement for their own information seeking and processing. A form of individual bias but often discussed as a group bias, or the larger effects on natural language processing models.",,
,,,,human reporting,-,When users rely on automation as a heuristic replacement for their own information seeking and processing.,,
,,,,presentation,-,"Biases arising from how information is presented on the Web, via a user interface, due to rating or ranking of output, or through users’ own self-selected, biased interaction.",,
,,,,ranking,-,A form of anchoring bias. The idea that top-ranked results are the most relevant and important and will result in more clicks than other results.,,
,,,GROUP,,-,,,
,,,,groupthink,-,"A psychological phenomenon that occurs when people in a group tend to make non-optimal decisions based on their desire to conform to the group, or fear of dissenting with the group. In groupthink, individuals often refrain from expressing their personal disagreement with the group, hesitating to voice opinions that do not align with the group.",,
,,,,funding,-,"Arises when biased results are reported in order to support or satisfy the funding agency or financial supporter of the research study, but it can also be the individual researcher.",,
,,,,"deployment",-,"Arises when systems are used as decision aids for humans, since the human intermediary may act on predictions in ways that are typically not modeled in the system. However, it is still individuals using the deployed system.",,
,,,,sunk cost fallacy,-,"A human tendency where people opt to continue with an endeavor or behavior due to previously spent or invested resources, such as money, time, and effort, regardless of whether costs outweigh benefits.",,
,,SYSTEMIC,,,-,Systemic biases result from procedures and practices of particular institutions that operate in ways which result in certain social groups being advantaged or favored and others being disadvantaged or devalued. This need not be the result of any conscious prejudice or discrimination but rather of the majority following existing rules or norms.,,
,,,,historical,-,"Referring to the long-standing biases encoded in society over time. Related to, but distinct from, biases in historical description, or the interpretation, analysis, and explanation of history.",,
,,,,societal,-,"Often referred to as social bias. Can be positive or negative, and take a number of different forms, but is typically characterized as being for or against groups or individuals based on social identities, demographic factors, or immutable physical characteristics. Societal or social biases are often stereotypes.",,
,,,,institutional,-,"In contrast to biases exhibited at the level of individual persons, institutional bias refers to a tendency exhibited at the level of entire institutions, where practices or norms result in the favoring or disadvantaging of certain social groups.",,
,,STATISTICAL/COMPUTATIONAL,,,-,"Statistical and computational biases stem from errors that result when the sample is not representative of the population. These biases arise from systematic as opposed to random error and can occur in the absence of prejudice, partiality, or discriminatory intent.",,
,,,PROCESSING/VALIDATATION,,-,,,
,,,,amplification,-,Arises when the distribution over prediction outputs is skewed in comparison to the prior distribution of the prediction target.,,
,,,,inherited,-,"Arises when applications that are built with machine learning are used to generate inputs for other machine learning algorithms. If the output is biased in any way, this bias may be inherited by systems using the output as input to learn other models.",,
,,,,error propagation,-,"Arises when applications that are built with machine learning are used to generate inputs for other machine learning algorithms. If the output is biased in any way, this bias may be inherited by systems using the output as input to learn other models",,
,,,,model selection,-,The bias introduced while using the data to select a single seemingly “best” model from a large set of models employing many predictor variables. Model selection bias also occurs when an explanatory variable has a weak relationship with the response variable.,,
,,,,survivorship,-,"Tendency for people to focus on the items, observations, or people that “survive” or make it past a selection process, while overlooking those that did not.",,
,,,USE AND INTERPRETATION,,-,,,
,,,,activity,-,"A type of selection bias that occurs when systems/platforms get their training data from their most active users, rather than those less active (or inactive).",,
,,,,concept drift,-,"Use of a system outside the planned domain of application, and a common cause of performance gaps between laboratory settings and the real world.",,
,,,,emergent,-,"Use of a system outside the planned domain of application, and a common cause of performance gaps between laboratory settings and the real world.",,
,,,,content production,-,"Arises from structural, lexical, semantic, and syntactic differences in the contents generated by users.",,
,,,,data dredging,-,A statistical bias in which testing huge numbers of hypotheses of a dataset may appear to yield statistical significance even when the results are statistically nonsignificant. ,,
,,,,feedback loop,-,Effects that may occur when an algorithm learns from user behavior and feeds that behavior back into the model.,,
,,,,linking,-,"Arises when network attributes obtained from user connections, activities, or interactions differ and misrepresent the true behavior of the users.",,
,,,SELECTION AND SAMPLING,,-,,,
,,,,data generation,-,Arises from the addition of synthetic or redundant data samples to a dataset.,,
,,,,detection,-,Systematic differences between groups in how outcomes are determined and may cause an over- or underestimation of the size of the effect.,,
,,,,ecological fallacy,-,Occurs when an inference is made about an individual based on their membership within a group.,,
,,,,evaluation,-,Arises when the testing or external benchmark populations do not equally represent the various parts of the user population or from the use of performance metrics that are not appropriate for the way in which the model will be used.,,
,,,,exclusion,-,When specific groups of user populations are excluded from testing and subsequent analyses.,,
,,,,measurement,-,"Arises when features and labels are proxies for desired quantities, potentially leaving out important factors or introducing group or input-dependent noise that leads to differential performance.",,
,,,,popularity,-,A form of selection bias that occurs when items that are more popular are more exposed and less popular items are under-represented.,,
,,,,population,-,Systematic distortions in demographics or other user characteristics between a population of users represented in a dataset or on a platform and some target population.,,
,,,,representation,-,"Arises due to non-random sampling of subgroups, causing trends estimated for one population to not be generalizable to data collected from a new population.",,
,,,,Simpson’s Paradox,-,A statistical phenomenon where the marginal association between two categorical variables is qualitatively different from the partial association between the same two variables after controlling for one or more other variables.,,
,,,,temporal,-,Bias that arises from differences in populations and behaviors over time.,,
,,,,uncertainty,-,"Arises when predictive algorithms favor groups that are better represented in the training data, since there will be less uncertainty associated with those predictions.",,
5. Trustworthy Artificial Intelligence: A Review,"DAVINDER KAUR, SULEYMAN USLU, KALEY J. RITTICHIER, ARJAN DURRESI",Data bias,,-,-,The first reason for the bias to occur is if the data on which the system is trained is biased. This happens when the data does not represent a clear picture of reality. This type of bias is called data bias.,,
,,,representation,-,-,Representation bias means that the data does not represent all segments of society equally.,,
,,,societal,-,-,Societal bias happens if the data correctly represents the society that is already biased.,,
,,Model bias,-,-,-,Model bias is if the algorithm itself introduces the bias. Model bias can occur because of a wrong objective function that does not capture the fundamental logic for the prediction or if one feature is given more priority than other features without any valid logic by the algorithm.,,
,,Evaluation bias,-,-,-,"Evaluation bias happens if the wrong evaluation metrics were used to evaluate the model or biased users, which affect the system through feedback loops if the users’ responses are partial toward any particular item due to societal stereotypes or peer pressure.",,
6. Journal of Business Research ,"Benjamin van Giffen, Dennis Herhausen,Tobias Fahse ",Social Bias,-,-,"Historical, Societal, Individual, Pre-existing",Available data reflects existing bias in the relevant population prior to the creation of the ML model. ,,
,,Measurement Bias,-,-,"Linking, Omitted Variable",Chosen features and labels are imperfect proxies for the real variables of interest.,,
,,Representation Bias,-,-,"Temporal, Longitudinal Data Fallacy, Emergent, Population, Group, Aggregation, Behavioral, Sampling, Content Production, (Self) Selection, Availability","The input data is not representative for the relevant population, which leads to systematic errors in ML model predictions.",,
,,Label Bias,-,-,-,Labelled data systematically deviate from the underlying truth categories.,,
,,Algorithmic Bias,-,-,"Statistical, Technical",Inappropriate technical considerations during modeling lead to systemic deviation of the outcome.,,
,,Evaluation Bias,-,-,"Observer, Funding",A nonrepresentative testing population or inappropriate performance metrics are used to evaluate the ML model.,,
,,Deployment Bias,-,-,Cause-Effect,The ML model is used and interpreted in a different context than it was built for.,,
,,Feedback Bias,-,-,"Presentation, User Interaction, Popularity, Ranking, Second Order",The outcome of the ML model influences the training data such that a small bias can be reinforced by a feedback loop.,,
7. A Review of Bias and Fairness in Artificial Intelligence,"Rubén González-Sendino, Emilio Serrano, Javier Bajo1, Paulo Novais",Human,,-,-,Human-made decisions that are reflected in the data or in the model.,,
,,,Historical,,-,,,
,,,,Cognitive,-,"Cognitive bias arises even when the data is perfectly measured and sampled, for example, reinforcing a stereotype.",,
,,,Content creation,,-,"Content creation bias is produced when users are guided by norms or functionalities, and sometimes these interactions are led by an AI system. Bias production in the future will be affected by unfair systems, generating new data to be used in future learning.",,
,,,,Behavior,-,"Behavior bias produces distortions from reality or other applications according to user connections, activities, or interactions. Furthermore, unconscious bias could be produced by content creation, because the way a child or an adult expresses themselves is different, in the same way as if you compare by sex or race.",,
,,Data,,-,-,"Data bias focuses on the factors that induce a biased dataset. The main tasks where data bias may occur are acquisition, querying, filtering, transforming, and cleaning.",,
,,,Sampling,-,-,Sample bias is produced when the train and test data do not represent or under-represent a population segment.,,
,,,Representation,-,-,The representation is not the only problem related to the data. ,,
,,Learning,,-,-,Learning biases are produced in model training.,,
,,,Aggregation,-,-,Aggregation bias amplifies the disparities between different examples in data samples.,,
,,,Evaluation,-,-,Evaluation bias occurs when the selected metrics are not appropriate.,,
,,Deployment,,-,-,"Deployment bias may occur in the deployment and use of the model. The algorithm makes decisions based on patterns learned from the data. Therefore, the deployment of a model in a different scenario with respect to data could lead to unfair results.",,
"8. Bias and Unfairness in Machine Learning Models: A Systematic Review on Datasets, Tools, Fairness Metrics, and Identification and Mitigation Methods","Tiago P. Pagano, Rafael B. Loureiro, Fernanda V. N. Lisboa, Rodrigo M. Peixoto, Guilherme A. S. Guimarães, Gustavo O. R. Cruz, Maira M. Araujo, Lucas L. Santos, Marco A. S. Cruz, Ewerton L. S. Oliveira, Ingrid Winkler, Erick G. S. Nascimento",,,,,,uses Mehrabi's categorization,
"9. Fairness issues, current approaches, and challenges in machine learning models","Tonni Das Jui, Pablo Rivas",Biased training data,,-,-,Bias in the data refers to the presence of systematic errors or inaccuracies that deplete the fairness of a model if we use these biased data to train a model.,,
,,,Measurement,-,-,Measurement bias is a potential source of data bias in ML that occurs when the measurements or assessments used to collect data systematically overestimate or underestimate the true value of the characteristic being measured.,,
,,,Representation,-,-,"Representation bias refers to the bias in a dataset or model that results from under or over-representing certain groups or characteristics in the data, which can lead to biased or inaccurate predictions for those group.","Sampling bias slightly difers from the representation 
bias [103, 131]. Sampling bias occurs when the sample data 
for training does not represent the population targeted to 
generalize. In contrast, representation bias is an inadequate 
representation of the real-world distribution of the data",
,,,Sampling,-,-,Sampling bias occurs when the sample data for training does not represent the population targeted to generalize.,,
,,,Label,-,-,Label bias occurs when the labels assigned to data instances are biased in some way.,,
,,,Aggregation,-,-,Aggregation bias occurs when a single model is used to generalize across diferent groups or subpopulations and can lead to sub-optimal performance for some groups.,,
,,Inherent,,-,-,,,
,,,Prediction inconsistency,-,-,Prediction inconsistency is a diferent type of bias addressed as leave-one-out unfairness.,,
,,,Historical discrimination,-,-,"Even if the algorithms used in decision making processes are unbiased, the data they are trained on may contain historical biases, leading to discriminatory outcomes.",,
,,Bias toward feature groups,-,-,-,,,
,,Decision model,,-,-,,,
,,,Algorithmic bias,-,-,Algorithmic bias is a potential bias that can introduce discrimination or unfairness in the model. It refers to the bias introduced by the algorithm rather than inherent in the input data.,,
,,,Hidden,-,-,"Despite having a balanced distribution in the dataset and being free of sensitive feature correlation, it still can contain hidden biases, which refer to the biases present in the data used to train an ML model that is not immediately apparent or identifable.",,
,,,Evaluation,-,-,"Evaluation bias refers to a type of bias that arises while evaluating machine learning models, and thus, it is not related to data bias.",,